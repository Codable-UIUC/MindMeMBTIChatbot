{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from senticnet.senticnet import SenticNet\n",
    "import re\n",
    "import string\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "#github test first commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)\n",
    "bert_model = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MBTI = pd.read_csv('mbti_1.csv')\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : 126 words as sentence  if exceeds 126, split it, if less than 126 apply padding of 0.\n",
    "# output : 128 * 768\n",
    "\n",
    "def bert_process(text_to_process):\n",
    "    text_preprocessed = bert_preprocess_model(text_to_process)\n",
    "    bert_results = bert_model(text_preprocessed)\n",
    "    tempres = (bert_results[\"sequence_output\"].numpy()).tolist()\n",
    "\n",
    "    return tempres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def senticnet(processedinput, sentences):\n",
    "    sn = SenticNet()\n",
    "    index = 0\n",
    "    # res = []\n",
    "    arrmodel = [float(0)] * 20\n",
    "\n",
    "    for i in range(len(processedinput)):\n",
    "        processedinput[i][0].extend(arrmodel)\n",
    "        processedinput[i][-1].extend(arrmodel)\n",
    "        for j in range(1,len(processedinput[i]) -1):\n",
    "            temparr = arrmodel\n",
    "            try:\n",
    "                cur_polarity_value = sn.polarity_value(sentences[index])\n",
    "                Eclass = int((float(cur_polarity_value) + 1)/0.1)\n",
    "                temparr[Eclass] = 1\n",
    "                processedinput[i][j].extend(temparr)\n",
    "            except:\n",
    "                processedinput[i][j].extend(temparr)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "    return processedinput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    regex = re.compile('[%s]' % re.escape('|'))\n",
    "    text = regex.sub(\" \", text)\n",
    "    words = str(text).split()\n",
    "    words = [i.lower() + \" \" for i in words]\n",
    "    words = [i for i in words if not \"http\" in i]\n",
    "    words = \" \".join(words)\n",
    "    words = words.translate(words.maketrans('', '', string.punctuation))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,3):\n",
    "    for post in MBTI[\"posts\"][100*(n-1):(100 * n)]:\n",
    "        sentences = []\n",
    "        sentence = clean_text(str(post))\n",
    "        sentence = sentence.split()\n",
    "        if len(sentence) < 756:\n",
    "            padd = ['0'] * (756-len(sentence))\n",
    "            sentence.extend(padd)\n",
    "        sentence = sentence[:756]\n",
    "        tempsentence = list(list_chunks(sentence, 126))\n",
    "        for wds in tempsentence:\n",
    "            sentences.append(' '.join(wds))\n",
    "        processedinput = bert_process(sentences)\n",
    "        tokenizedoutput = senticnet(processedinput, sentence)\n",
    "        data.append(tokenizedoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "IElabels = []\n",
    "NSlabels = []\n",
    "FTlabels = []\n",
    "JPlabels = []\n",
    "\n",
    "templabels = MBTI[\"type\"]\n",
    "# labelmap = {\"INTJ\" : 0.0, \"INTP\": 1.0, \"ENTJ\": 2.0, \"ENTP\" : 3.0, \"INFJ\": 4.0, \"INFP\": 5.0, \"ENFJ\": 6.0, \"ENFP\": 7.0, \"ISTJ\": 8.0, \"ISFJ\": 9.0, \"ESTJ\": 10.0, \"ESFJ\": 11.0, \"ISTP\": 12.0, \"ISFP\": 13.0, \"ESTP\": 14.0, \"ESFP\": 15.0}\n",
    "# labeindex = [\"INTJ\", \"INTP\", \"ENTJ\", \"ENTP\", \"INFJ\", \"INFP\", \"ENFJ\", \"ENFP\", \"ISTJ\", \"ISFJ\", \"ESTJ\", \"ESFJ\", \"ISTP\", \"ISFP\", \"ESTP\", \"ESFP\"]\n",
    "labelmap = {\"I\" : 0.0, \"E\": 1.0, \"N\": 2.0, \"S\" : 3.0, \"F\": 4.0, \"T\": 5.0, \"J\": 6.0, \"P\": 7.0}\n",
    "\n",
    "for l in templabels:\n",
    "    IElabels.append(labelmap[l[0]])\n",
    "    NSlabels.append(labelmap[l[1]])\n",
    "    FTlabels.append(labelmap[l[2]])\n",
    "    JPlabels.append(labelmap[l[3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = data[:190]\n",
    "testdata = data[190:200]\n",
    "trainlabel = IElabels[:190]\n",
    "testlabel = IElabels[190:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traindata = data\n",
    "# trainlabel = labels[200:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(traindata))\n",
    "\n",
    "# print(len(trainlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = tf.convert_to_tensor(traindata)\n",
    "testdata = tf.convert_to_tensor(testdata)\n",
    "trainlabel = tf.convert_to_tensor(trainlabel)\n",
    "testlabel = tf.convert_to_tensor(testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 5\n",
    "# batch_size = 20\n",
    "# learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(6, 5, (1,3))\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(5, 4, 3)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv3 = nn.Conv2d(4, 3, (3,1))\n",
    "\n",
    "#         self.fc1 = nn.Linear(6 * 3 * 3, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # -> n, 3, 32, 32\n",
    "#         x = nn.LeakyReLU(self.conv1(x)) # -> n, 6, 14, 14\n",
    "#         x = nn.LeakyReLU(self.conv2(x))  # -> n, 16, 5, 5\n",
    "#         print(x.shape())\n",
    "#         x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "#         x = F.relu(self.fc1(x))               # -> n, 120\n",
    "#         x = F.relu(self.fc2(x))               # -> n, 84\n",
    "#         x = self.fc3(x)                       # -> n, 10\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(traindata, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs = data\n",
    "#         labels = trainlabel[i]\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "#             running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './cnn.pth'\n",
    "# torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0\n",
    "#     n_class_correct = [0 for i in range(10)]\n",
    "#     n_class_samples = [0 for i in range(10)]\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         # max returns (value ,index)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         n_samples += labels.size(0)\n",
    "#         n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "#         for i in range(batch_size):\n",
    "#             label = labels[i]\n",
    "#             pred = predicted[i]\n",
    "#             if (label == pred):\n",
    "#                 n_class_correct[label] += 1\n",
    "#             n_class_samples[label] += 1\n",
    "\n",
    "#     acc = 100.0 * n_correct / n_samples\n",
    "#     print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "#     for i in range(10):\n",
    "#         acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "#         print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(traindata))\n",
    "# print(type(trainlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "iemodel = models.Sequential()\n",
    "iemodel.add(layers.Conv2D(32, (1, 3), activation='sigmoid', input_shape=traindata.shape[1:]))\n",
    "iemodel.add(layers.Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "iemodel.add(layers.Conv2D(32, (3, 1), activation='sigmoid'))\n",
    "# fully connected layer\n",
    "iemodel.add(layers.Flatten())\n",
    "iemodel.add(layers.Dense(128, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 6, 126, 32)        75680     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 124, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 124, 32)        3104      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7936)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               1015936   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,103,968\n",
      "Trainable params: 1,103,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "iemodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "iemodel.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/keras/backend.py:5586: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 8s 539ms/step - loss: 1.3947 - accuracy: 0.5737 - val_loss: 1.1014 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 2s 265ms/step - loss: 0.7297 - accuracy: 0.7158 - val_loss: 0.3288 - val_accuracy: 0.9000\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 2s 272ms/step - loss: 0.6299 - accuracy: 0.6684 - val_loss: 0.3399 - val_accuracy: 0.9000\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 2s 302ms/step - loss: 0.6302 - accuracy: 0.6789 - val_loss: 0.6792 - val_accuracy: 0.7000\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 0.5849 - accuracy: 0.7737 - val_loss: 0.3357 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history = iemodel.fit(traindata, trainlabel, epochs=5, \n",
    "                    validation_data=(testdata, testlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    }
   ],
   "source": [
    "# history = iemodel.fit(traindata, trainlabel, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iemodel.save(\"my_iemodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post = MBTI[\"posts\"][1505]\n",
    "# sentences = []\n",
    "# sentence = clean_text(str(post))\n",
    "# sentence = sentence.split()\n",
    "# if len(sentence) < 756:\n",
    "#     padd = ['0'] * (756-len(sentence))\n",
    "#     sentence.extend(padd)\n",
    "# sentence = sentence[:756]\n",
    "# tempsentence = list(list_chunks(sentence, 126))\n",
    "# for wds in tempsentence:\n",
    "#     sentences.append(' '.join(wds))\n",
    "# processedinput = bert_process(sentences)\n",
    "# tokenizedoutput = senticnet(processedinput, sentence)\n",
    "# data.append(tokenizedoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = [data[-1]]\n",
    "# sample = tf.convert_to_tensor(sample)\n",
    "\n",
    "# samplea = [labelmap[MBTI[\"type\"][1505]]]\n",
    "# samplea = tf.convert_to_tensor(samplea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step - loss: 2.6632 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# results = model.evaluate(sample, samplea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n",
      "4.0\n",
      "[[7.5876746 7.1726966 4.733189  9.027504  6.875262  6.8005047 4.7541246\n",
      "  3.2605245 0.        3.5965374 0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# result = model.predict(sample)\n",
    "# print(labelmap[MBTI[\"type\"][1505]])\n",
    "# print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa30329a179dc72b3ae876673999c5ab6f16f338907d2ffefe9c1147fc6ab467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
